{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet, enet_path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV, Lasso, \\\n",
    "    lasso_path\n",
    "from sklearn.linear_model import enet_path\n",
    "from functions_Lasso import LSLassoCV\n",
    "SEED = 11235813\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "x_true = np.array([3]*15 + [0]*25)\n",
    "sigma = 1\n",
    "w = np.random.rand(50)\n",
    "z1, z2, z3 = np.random.rand(n), np.random.rand(n), np.random.rand(n)\n",
    "Z1 = np.tile(z1.reshape(n, -1), 5)\n",
    "Z2 = np.tile(z2.reshape(n, -1), 5)\n",
    "Z3 = np.tile(z2.reshape(n, -1), 5)\n",
    "W1, W2, W3 = np.random.rand(n, 5), np.random.rand(n, 5), np.random.rand(n, 5)\n",
    "W = np.random.rand(n, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.24270664 20.87666339 21.38127718 35.40223711 12.03572087 37.34489217\n",
      "  8.8946578  32.72383628 22.25719717 35.56643322 22.25066035 20.06415322\n",
      " 14.1242941  22.16264981 32.1887602  27.91604737 31.88146033 33.32917379\n",
      " 24.19220136 36.27490426 16.18089201  9.98728441 15.12594486 28.70988733\n",
      " 27.61046091 19.09295567  8.96437552 28.78428383 21.85884446 28.58215163\n",
      " 12.43574463 21.84989679 42.76027449 42.457323   26.6291835  32.11106773\n",
      " 28.29845252 10.88121175 19.63024386 39.68673809 38.44314051 11.79595847\n",
      " 24.9112905  32.32350744 34.66134648 27.67450321 25.47805499 20.74612162\n",
      "  8.19228953 19.32029332]\n"
     ]
    }
   ],
   "source": [
    "A = np.concatenate((Z1 + .01 * W1, Z2 + .01 * W2, Z3 + .01 * W3, W ),\n",
    "                   axis=1)\n",
    "b = A @ x_true + sigma * w\n",
    "print(b)\n",
    "\n",
    "alpha = np.array([0.01 * 1.58 ** l for l in range(1,11)])\n",
    "lambda_ = np.array([0.01 * 2 ** l for l in range(1,16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = [(alpha[i], lambda_[j]) for i in range(len(alpha)) for j in range(len(lambda_))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0158, 0.02), (0.0158, 0.04), (0.0158, 0.08), (0.0158, 0.16), (0.0158, 0.32), (0.0158, 0.64), (0.0158, 1.28), (0.0158, 2.56), (0.0158, 5.12), (0.0158, 10.24), (0.0158, 20.48), (0.0158, 40.96), (0.0158, 81.92), (0.0158, 163.84), (0.0158, 327.68), (0.024964000000000004, 0.02), (0.024964000000000004, 0.04), (0.024964000000000004, 0.08), (0.024964000000000004, 0.16), (0.024964000000000004, 0.32), (0.024964000000000004, 0.64), (0.024964000000000004, 1.28), (0.024964000000000004, 2.56), (0.024964000000000004, 5.12), (0.024964000000000004, 10.24), (0.024964000000000004, 20.48), (0.024964000000000004, 40.96), (0.024964000000000004, 81.92), (0.024964000000000004, 163.84), (0.024964000000000004, 327.68), (0.039443120000000005, 0.02), (0.039443120000000005, 0.04), (0.039443120000000005, 0.08), (0.039443120000000005, 0.16), (0.039443120000000005, 0.32), (0.039443120000000005, 0.64), (0.039443120000000005, 1.28), (0.039443120000000005, 2.56), (0.039443120000000005, 5.12), (0.039443120000000005, 10.24), (0.039443120000000005, 20.48), (0.039443120000000005, 40.96), (0.039443120000000005, 81.92), (0.039443120000000005, 163.84), (0.039443120000000005, 327.68), (0.06232012960000002, 0.02), (0.06232012960000002, 0.04), (0.06232012960000002, 0.08), (0.06232012960000002, 0.16), (0.06232012960000002, 0.32), (0.06232012960000002, 0.64), (0.06232012960000002, 1.28), (0.06232012960000002, 2.56), (0.06232012960000002, 5.12), (0.06232012960000002, 10.24), (0.06232012960000002, 20.48), (0.06232012960000002, 40.96), (0.06232012960000002, 81.92), (0.06232012960000002, 163.84), (0.06232012960000002, 327.68), (0.09846580476800001, 0.02), (0.09846580476800001, 0.04), (0.09846580476800001, 0.08), (0.09846580476800001, 0.16), (0.09846580476800001, 0.32), (0.09846580476800001, 0.64), (0.09846580476800001, 1.28), (0.09846580476800001, 2.56), (0.09846580476800001, 5.12), (0.09846580476800001, 10.24), (0.09846580476800001, 20.48), (0.09846580476800001, 40.96), (0.09846580476800001, 81.92), (0.09846580476800001, 163.84), (0.09846580476800001, 327.68), (0.15557597153344005, 0.02), (0.15557597153344005, 0.04), (0.15557597153344005, 0.08), (0.15557597153344005, 0.16), (0.15557597153344005, 0.32), (0.15557597153344005, 0.64), (0.15557597153344005, 1.28), (0.15557597153344005, 2.56), (0.15557597153344005, 5.12), (0.15557597153344005, 10.24), (0.15557597153344005, 20.48), (0.15557597153344005, 40.96), (0.15557597153344005, 81.92), (0.15557597153344005, 163.84), (0.15557597153344005, 327.68), (0.2458100350228353, 0.02), (0.2458100350228353, 0.04), (0.2458100350228353, 0.08), (0.2458100350228353, 0.16), (0.2458100350228353, 0.32), (0.2458100350228353, 0.64), (0.2458100350228353, 1.28), (0.2458100350228353, 2.56), (0.2458100350228353, 5.12), (0.2458100350228353, 10.24), (0.2458100350228353, 20.48), (0.2458100350228353, 40.96), (0.2458100350228353, 81.92), (0.2458100350228353, 163.84), (0.2458100350228353, 327.68), (0.38837985533607977, 0.02), (0.38837985533607977, 0.04), (0.38837985533607977, 0.08), (0.38837985533607977, 0.16), (0.38837985533607977, 0.32), (0.38837985533607977, 0.64), (0.38837985533607977, 1.28), (0.38837985533607977, 2.56), (0.38837985533607977, 5.12), (0.38837985533607977, 10.24), (0.38837985533607977, 20.48), (0.38837985533607977, 40.96), (0.38837985533607977, 81.92), (0.38837985533607977, 163.84), (0.38837985533607977, 327.68), (0.613640171431006, 0.02), (0.613640171431006, 0.04), (0.613640171431006, 0.08), (0.613640171431006, 0.16), (0.613640171431006, 0.32), (0.613640171431006, 0.64), (0.613640171431006, 1.28), (0.613640171431006, 2.56), (0.613640171431006, 5.12), (0.613640171431006, 10.24), (0.613640171431006, 20.48), (0.613640171431006, 40.96), (0.613640171431006, 81.92), (0.613640171431006, 163.84), (0.613640171431006, 327.68), (0.9695514708609896, 0.02), (0.9695514708609896, 0.04), (0.9695514708609896, 0.08), (0.9695514708609896, 0.16), (0.9695514708609896, 0.32), (0.9695514708609896, 0.64), (0.9695514708609896, 1.28), (0.9695514708609896, 2.56), (0.9695514708609896, 5.12), (0.9695514708609896, 10.24), (0.9695514708609896, 20.48), (0.9695514708609896, 40.96), (0.9695514708609896, 81.92), (0.9695514708609896, 163.84), (0.9695514708609896, 327.68)]\n"
     ]
    }
   ],
   "source": [
    "print(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9943135649322976, 0.9945413564414018, 0.9947732022648637, 0.9950046646591231, 0.9952326318172675, 0.995456521684109, 0.9956769384842552, 0.9958565910065306, 0.9960308365423203, 0.9961953764534889, 0.9963543810700072, 0.9965108939617603, 0.9966647996097313, 0.9968262051962553, 0.996990716610128, 0.9971384808336344, 0.9972794572720607, 0.9974159423344828, 0.9975471568343067, 0.9976729549937423, 0.9977924432520645, 0.9979069564088676, 0.9980166868069649, 0.9981197857258464, 0.9982093266426387, 0.9982958094153994, 0.9983791158224435, 0.998459215418092, 0.9985355873760009, 0.9986014570085082, 0.9986584193948805, 0.9987132950409215, 0.9987709429210901, 0.9988220297439183, 0.9988617674068605, 0.998899002103269, 0.9989337346585347, 0.9989653685843765, 0.9989940853019549, 0.9990203129977036, 0.9990483054374232, 0.9990743767642338, 0.9990956927802808, 0.9991086164969203, 0.9991146362626082, 0.9991195795560962, 0.9991238213299415, 0.9991281379129843, 0.9991320914094232, 0.9991717628306662, 0.9818540667924371, 0.9824130124265268, 0.9829914758469672, 0.9835810274045523, 0.9841706522449201, 0.9847630063185929, 0.9853546825730749, 0.9859466421956731, 0.9865304905000437, 0.9871117987562856, 0.9876920904749855, 0.988271739341539, 0.9888651141017969, 0.9894537972389292, 0.9900378809998346, 0.9906149691167936, 0.9911933877727216, 0.9917671734494166, 0.9922683701726391, 0.9927405355176767, 0.9932064141800246, 0.9936657101663232, 0.9941167971601708, 0.9945646803634263, 0.9950233286054786, 0.9954618590922286, 0.9958603418804561, 0.9962518727909166, 0.9966294892141062, 0.9969911683010136, 0.9973026089439622, 0.9975652789561922, 0.9977984879231392, 0.9980133224750956, 0.9982049431328209, 0.9983576396517978, 0.998487605410825, 0.9985962803935577, 0.9986848450165607, 0.9987330397357391, 0.9987692134616866, 0.9987973826959844, 0.9988252547047298, 0.9988562689051448, 0.9988860966920963, 0.9989146801882157, 0.9989421264144203, 0.9989682421597907, 0.9989921530879823, 0.9990402751816824, 0.9707775306013381, 0.9715483475590448, 0.9723522942679527, 0.9731749298229547, 0.9740023975508411, 0.9748348643737357, 0.9756724198053083, 0.9765244322332078, 0.9773815205749935, 0.9782431767879661, 0.9791087841298133, 0.979977584501723, 0.9808475462032992, 0.9817124651226183, 0.9825733953446678, 0.9834347788453411, 0.9842698114429095, 0.9851128859550734, 0.9859816466667574, 0.9868738572086561, 0.9877354397222052, 0.9885653741676435, 0.9894005457916939, 0.990226044686918, 0.9910382900269342, 0.9918349001798786, 0.9926111131961141, 0.9933028560454497, 0.9939743983408781, 0.9945957514353544, 0.9951470196807485, 0.9955809893358925, 0.9959576945690989, 0.9963138042876978, 0.9966334576344889, 0.9969141476930387, 0.9971765799906167, 0.9973897989067125, 0.997574555362991, 0.9977498459802486, 0.9978781883081087, 0.9979706412793156, 0.9980626373291722, 0.9981567353055686, 0.9982475391020118, 0.9983348076142631, 0.9984109564240975, 0.9984753822958443, 0.9985367428125566, 0.9985171538513382, 0.9602031325472938, 0.9611379830517618, 0.9620988706311129, 0.9631062609700497, 0.9641250405432829, 0.9651502197915475, 0.9661946587995359, 0.9672468268909686, 0.9683089374178084, 0.9693788798818503, 0.9704567575096962, 0.9715348279192785, 0.972611985958908, 0.9736965531892514, 0.9747666980485448, 0.9758345161975008, 0.9769094907890987, 0.9780819405070263, 0.9792698426333741, 0.9804645022020665, 0.9817356163175619, 0.9829406765226607, 0.9840993802498151, 0.9852345107120823, 0.9863563292933248, 0.9874654481596696, 0.9885530132861994, 0.9895239180865796, 0.9904489028861826, 0.9912611877577826, 0.9919799920453624, 0.9926526865435703, 0.9931909541677283, 0.9937071334151238, 0.9942058338578232, 0.9946847555925272, 0.995122811601307, 0.9954775903805128, 0.9958141205011142, 0.996145106110857, 0.9964610839383677, 0.9966626921284206, 0.996849040471158, 0.99700542498711, 0.9971514641749151, 0.9972929746929047, 0.9974298534115014, 0.9975621946793343, 0.9976904150786469, 0.9974827687129643, 0.9498185547642107, 0.9508911145889398, 0.9519805248456459, 0.9531360556292207, 0.954312649311851, 0.9554992315104943, 0.9567081071056361, 0.957929597047151, 0.9591634957637585, 0.9604094976969666, 0.9616559674600629, 0.9629060863904242, 0.9641722627093801, 0.965415928155963, 0.9666755596472862, 0.9679675486830183, 0.9693714442545899, 0.9707901264707965, 0.9722472319545206, 0.9737594145483301, 0.9753042988030025, 0.9768314436457303, 0.9782710070519933, 0.9797091957535744, 0.9811077289153025, 0.9824617801686462, 0.9838026172471633, 0.9850310549572134, 0.9861459544630052, 0.9871898473534113, 0.9880782898578617, 0.9889034898389875, 0.9896624043267755, 0.9904004467757309, 0.9911195523826954, 0.9918020728915682, 0.9924296965673515, 0.9929624533378709, 0.9935039309141034, 0.9940293403277405, 0.9945219442087461, 0.9948488461936348, 0.9951019898400241, 0.995349330953049, 0.9955906728696176, 0.995825767569385, 0.9960539620054335, 0.996274889938076, 0.9964894602987603, 0.9960861956895427, 0.9395163822186028, 0.9407129417590399, 0.9419278667341757, 0.9431877727911394, 0.9445001770682263, 0.9458291477926669, 0.9471811142540498, 0.9485501064007296, 0.9499300888205807, 0.9513240886273907, 0.9527169854910096, 0.9541268168102495, 0.9555236707187171, 0.9569593556660256, 0.9584140190623801, 0.9599983293643941, 0.9616044263908178, 0.9632842897604609, 0.9650050850593351, 0.9667505014089376, 0.9685475868603687, 0.9703412677050641, 0.9720378988836882, 0.9736928751781345, 0.9753346535734737, 0.9769514183251903, 0.9785276393980015, 0.9799259788830992, 0.9812954686627638, 0.9824331704445737, 0.9835035675046166, 0.9845661361256941, 0.985546955923677, 0.9865123465677673, 0.9874445591413126, 0.9883555688960377, 0.989181940812832, 0.9899426548819416, 0.9906897428368407, 0.9914166600069475, 0.9920235442166758, 0.9925198667256828, 0.9928889107457035, 0.993250844514592, 0.9936052949577072, 0.993951807110567, 0.9942894988937224, 0.9946179867813986, 0.9949363293414984, 0.9945400061442489, 0.9292697241708346, 0.9305792452046274, 0.9319015416537336, 0.9332454979314994, 0.9346821967301815, 0.9361393487607756, 0.9376143379663282, 0.9391124946365716, 0.9406293419510763, 0.9421458607113388, 0.9436723733180656, 0.9452166572197545, 0.946776491516678, 0.9483601509130359, 0.9500908098670907, 0.9518527376855153, 0.9537108541938553, 0.9556055070302781, 0.9575308907037703, 0.9595011080556272, 0.9615235102366891, 0.9635417559173036, 0.9654046867103229, 0.9672832388340281, 0.969170207604228, 0.9710437627227689, 0.9727519044838971, 0.9743858998114184, 0.9758365242255246, 0.9771361191597009, 0.9784359166930031, 0.9797196558860182, 0.980923330548724, 0.982106255217763, 0.983263347067982, 0.9844174419015181, 0.9854613590275905, 0.9864379139137003, 0.9873984171867666, 0.9882473546579911, 0.9890434050128167, 0.9897351426149968, 0.9902341099710034, 0.9907250090921144, 0.9912073494202043, 0.9916805002856499, 0.9921438274731922, 0.9925954778671312, 0.9930336549140829, 0.992665928397224, 0.9190780806453352, 0.9204868844711163, 0.9219051506725701, 0.9233394818512957, 0.9248636103484817, 0.9264347091876585, 0.928027208198757, 0.9296379457356349, 0.9312680242403648, 0.9328944876794623, 0.9345667591441763, 0.9362318882041715, 0.937923136755871, 0.9397514677586114, 0.9416399747883961, 0.9436431628016997, 0.9456801258814571, 0.9477501230404569, 0.9498528058080418, 0.9520442521414508, 0.9542725814184384, 0.9564082334305368, 0.958483095436829, 0.9605811145736987, 0.96269157663546, 0.9646956805156804, 0.9666269994106751, 0.9683666826774733, 0.9699094980687929, 0.9714241907492575, 0.9729434915930664, 0.9744304017438001, 0.9758535078930087, 0.9772460941893412, 0.9786393410414129, 0.9800468344265804, 0.9812911948630849, 0.9824893359798422, 0.9835723849740006, 0.9846329965341394, 0.9856236139549668, 0.9865151930792218, 0.9871550902470514, 0.9877864541722579, 0.9884087059878965, 0.989021160066513, 0.9896227561644694, 0.9902114568619774, 0.9907836188757999, 0.9904694516679026, 0.9089524809747, 0.9104433346732629, 0.9119509603301483, 0.9134698537353962, 0.915061154232182, 0.9167337048121924, 0.9184317147124426, 0.9201435970691771, 0.9218688184134283, 0.9236243903255693, 0.9254019412639878, 0.9271779225939486, 0.9290705503243087, 0.9310610743996257, 0.9331747744885097, 0.9353240707559524, 0.9375137988651268, 0.9397422951642588, 0.9420384320685882, 0.9444169586492506, 0.9467587983577613, 0.9490573071811779, 0.9513271348327818, 0.9536274498150117, 0.9558807332939554, 0.9580657196044633, 0.9601208289301831, 0.9619266291840534, 0.9636341780762996, 0.9653531899076828, 0.9670808816811143, 0.9687552655386884, 0.9703780812400793, 0.9719857351400901, 0.973650132128504, 0.9752763174616472, 0.9767105039181788, 0.9780456347900662, 0.9793273753876086, 0.9806044538713657, 0.9817903509470484, 0.9828793585111781, 0.9836685950964327, 0.9844492507386976, 0.9852207941621415, 0.9859824318806882, 0.9867329246844444, 0.9874698345804723, 0.9881882656997112, 0.987955096795121, 0.8989025590879025, 0.9004664638614626, 0.9020485788056261, 0.9036425970904326, 0.9052897126571798, 0.9070573875213346, 0.9088441093943794, 0.9106516072093696, 0.912479071501037, 0.9143419975894238, 0.9162035243647646, 0.9181241698393722, 0.9201919845325084, 0.9223849344800935, 0.9246266930153398, 0.9269106086974913, 0.9292381356234091, 0.9316099881250098, 0.9341008932307403, 0.9365862111127762, 0.9390877322645816, 0.9415292472440772, 0.9439783078915123, 0.9464492129735073, 0.9488168291022198, 0.9511914724494297, 0.9532683476967969, 0.9551706348031833, 0.9570592377548575, 0.958967978256433, 0.9608950324802636, 0.9627393881318304, 0.9645492341149171, 0.9664031510347268, 0.9683097911072789, 0.970116397611092, 0.9717081280103483, 0.9731982948486206, 0.974693580521579, 0.9761893040455194, 0.9775679609061512, 0.9788466933906816, 0.9797906024072381, 0.9807269147036153, 0.981654740408827, 0.9825731816654342, 0.9834809212902845, 0.9843755571927426, 0.9852493378179202, 0.985123345873661, 0.8889433034140152, 0.8905705290004532, 0.8922103949036909, 0.8938753903747927, 0.8955691818268248, 0.8974104943423453, 0.8992847094471699, 0.9011910422116357, 0.9031060614888298, 0.9050570410702343, 0.9069922226113135, 0.9091080542681, 0.911350898597916, 0.9136642527421084, 0.9160194438215844, 0.9184259830586077, 0.9208763768602356, 0.9234151539992455, 0.9260229800778346, 0.9286282539453694, 0.9312774208406079, 0.9338477674311284, 0.9364611577617519, 0.9390194941577836, 0.9415633457594218, 0.9439946523657025, 0.9461145891167775, 0.9481566713969479, 0.9502186037980982, 0.9523077815801707, 0.9544081984020392, 0.9564129449958582, 0.9584178610940624, 0.9605202133091544, 0.9626441453208727, 0.9646046981738537, 0.9662990308335987, 0.9679921091271038, 0.9696983331431507, 0.9714077650490519, 0.9729780947211377, 0.974434352682413, 0.9755365614918303, 0.9766324660129934, 0.9777212712683284, 0.9788018744138965, 0.9798729777810201, 0.980931675590103, 0.9819694232025367, 0.9819651327651916, 0.879080283493342, 0.880760475063492, 0.882461409134426, 0.8841765033943949, 0.8859225475224838, 0.8878243231631234, 0.8897678375512228, 0.8917701401120179, 0.8937613467267309, 0.895779967942609, 0.8978666755471557, 0.9001349528573847, 0.9024993976047326, 0.9049133301686043, 0.9073708309171509, 0.9098810468739339, 0.9124476394102121, 0.915154286320613, 0.9178403843068849, 0.9205787514778856, 0.923327343170671, 0.9260406732527967, 0.9287838094853711, 0.931439598719904, 0.9340966108179257, 0.9365511897662161, 0.9387402635940573, 0.9409259727843061, 0.9431487104988971, 0.9454033948087854, 0.9476433067510814, 0.9498095984748144, 0.9520506961443923, 0.9543572032341912, 0.9566680232012952, 0.9586904039765793, 0.9605634397277473, 0.9624559411000948, 0.9643681954008868, 0.9662664633095656, 0.9680417165188128, 0.969659612772515, 0.9709212454413646, 0.9721786649652469, 0.9734308626895344, 0.9746767958650132, 0.9759150445014687, 0.9771425937700488, 0.9783497741045645, 0.978480223098916, 0.8693291892279584, 0.8710539264084017, 0.8728005327191035, 0.8745632185816766, 0.8763600679587751, 0.8783003295990935, 0.8803349177618773, 0.8823965670946146, 0.8844518805305585, 0.8865319607192647, 0.8887979499273672, 0.8911974795388791, 0.8936418318155827, 0.8961434416057509, 0.8986939606058253, 0.9013043119820279, 0.9040156471960418, 0.9067918601949422, 0.9095906521380094, 0.9124555750530867, 0.9152874640437818, 0.9181310212289994, 0.9209399509795507, 0.9237345485406865, 0.9264277146799756, 0.928882485689272, 0.9311784922591612, 0.9335064651978026, 0.9358759363402375, 0.938288768386994, 0.9406450567857665, 0.9429844216393067, 0.9454414124799613, 0.947941701169543, 0.950412248691172, 0.9524702381043748, 0.954525817166342, 0.9566114239994836, 0.9587257185354084, 0.9608004888738133, 0.9627764130380914, 0.9645383050702764, 0.965959051464648, 0.9673774135661223, 0.9687935030946121, 0.9702060116095335, 0.9716133715173436, 0.9730125083493825, 0.9743924086771198, 0.9746686735845858, 0.8596982492911236, 0.8614595422343647, 0.8632437203197708, 0.8650454888578654, 0.8668852773602101, 0.8688636966739459, 0.8709671676359938, 0.8730858602438991, 0.8751963253685398, 0.87740549384501, 0.8798063413422145, 0.8822771862109147, 0.8848020568500085, 0.8873757573989915, 0.8900129205180662, 0.8927032810931217, 0.8955548043144301, 0.8983924236559656, 0.9013008209667034, 0.9042714373809859, 0.9071773529480256, 0.9101371934952321, 0.912998124000456, 0.9158685785577938, 0.9186075196644607, 0.9210529400830895, 0.9234630085014671, 0.9259210995256343, 0.9284272824291632, 0.9309819179519356, 0.9334368194517291, 0.9359824573410609, 0.9386123029523464, 0.941295296734697, 0.943787294137726, 0.9459829784236632, 0.9482149663532196, 0.9504857118874911, 0.9527924600723584, 0.9550297515969364, 0.9572022322142508, 0.9590859412180286, 0.9606628034368868, 0.9622407734733783, 0.9638191303095573, 0.965397427313934, 0.9669737554876662, 0.9685450243228885, 0.9700996261827846, 0.970530314623043, 0.8501942149920453, 0.8519844848417772, 0.8537940183768418, 0.8556318257778674, 0.8575070641081998, 0.8595290930725706, 0.8616805258404243, 0.8638479197598288, 0.8660049750060996, 0.8683851289313516, 0.8708581383530292, 0.8733909947170528, 0.8759806457262088, 0.8786225231663888, 0.8813308686839781, 0.8841509955510882, 0.8870470791317348, 0.8899797826791599, 0.8929762888957723, 0.8960078643871824, 0.8990071284680916, 0.9020089535604057, 0.9049843879495056, 0.907866261214909, 0.9105816020528366, 0.9130961069257704, 0.915618002249176, 0.9181937006954255, 0.9208229427802662, 0.9234708425916051, 0.9260674353036257, 0.9287963924046092, 0.9315877707518969, 0.9344169200304547, 0.9368949173253291, 0.9392490361962778, 0.9416481218687269, 0.9440927869671533, 0.9465858685963298, 0.9489751703790168, 0.9513333626145214, 0.9533175389243282, 0.9550459006691381, 0.9567794513414039, 0.9585171441913426, 0.9602587790189889, 0.9620021560878143, 0.9637444957264055, 0.9654737235707942, 0.9660652250269086, 0.840822117615042, 0.8426306831021297, 0.8444674538391066, 0.8463291343623748, 0.8482350387352837, 0.8502916489492629, 0.8524781838040543, 0.854689808086922, 0.8569426849755297, 0.8594390882749283, 0.8619628712903995, 0.8645488454959168, 0.8671941696246055, 0.8698948129903816, 0.8726649099815041, 0.8756106900557149, 0.8785431791734317, 0.8815547569584339, 0.8846348720363305, 0.887707047847855, 0.8907966110454225, 0.8938364903800641, 0.8968664461577041, 0.8997733488167955, 0.902447101611882, 0.9050349585790732, 0.9076576715363976, 0.9103399166360537, 0.9130831828359067, 0.9158002680610945, 0.9185750028202896, 0.9214441493674977, 0.9243851664389732, 0.927236557743877, 0.9297887748664325, 0.9322893025733054, 0.9348452019725821, 0.9374563549782357, 0.9401263585749079, 0.942647600104374, 0.9451895148148293, 0.9472475403730335, 0.9491211367619037, 0.951004670625457, 0.9528972647495644, 0.954797398280909, 0.9567041864458125, 0.9586145126891502, 0.9605155775542478, 0.9612735359356845, 0.8315849404443273, 0.8334116528448665, 0.8352640046477219, 0.8371425590014823, 0.8390829658315453, 0.8411537914204917, 0.8433770712010729, 0.8456178287408734, 0.848029783268003, 0.850557600867886, 0.8531287473475697, 0.8557592987895262, 0.8584463398782893, 0.8612023810179801, 0.8640791626382869, 0.8670495457310288, 0.8700533718476685, 0.8731341670484023, 0.8762878346363624, 0.8793892106440035, 0.8825388638129373, 0.8856225785936905, 0.8886502180314373, 0.8915249473875596, 0.8942383730789392, 0.8968897115957881, 0.8996019926784, 0.9023829807894314, 0.9052267188842081, 0.9080242216342362, 0.910947477275097, 0.9139441037440664, 0.9170141891693473, 0.9198771878943042, 0.9224862083462382, 0.925124462481375, 0.9278267159847602, 0.9305939801566294, 0.9334197843292888, 0.936067105756951, 0.9387794049862108, 0.9408879924457971, 0.9429008896622367, 0.9449260810514728, 0.9469678146253171, 0.9490206057441628, 0.9510855306658047, 0.9531589342795692, 0.9552275946021735, 0.9561550550910536, 0.8224873165056554, 0.8243239852753345, 0.8261865385269186, 0.8280751492015839, 0.830049720623915, 0.8321288839239406, 0.8343770160476088, 0.8366360971159826, 0.8392055076108897, 0.8417569972155431, 0.8443624960791805, 0.8470252049992537, 0.8497560690476876, 0.8525535743357529, 0.8555355289760244, 0.8585264939747023, 0.8615866531221519, 0.8647215771874721, 0.8679004653320299, 0.8710650625182563, 0.874227719783837, 0.8773840780481555, 0.8803880029665204, 0.8831865166939397, 0.8859520827417667, 0.8886749625667721, 0.8914703647049845, 0.894330618685369, 0.8972385772916718, 0.9001647510734444, 0.9031966830477708, 0.9063133700866959, 0.9093898943657521, 0.9123081917563062, 0.915005089507277, 0.9177698020483965, 0.9206070328882072, 0.9235171784053993, 0.9264479303365729, 0.9292463556548368, 0.9321212383663424, 0.9342535394910151, 0.9363955583483825, 0.9385563508046437, 0.9407379340551419, 0.9429360489653251, 0.9451515960200488, 0.9473814360837789, 0.9496118281823643, 0.9507098874668429, 0.8135304248567169, 0.8153714216923017, 0.8172385065731993, 0.8191353809952505, 0.8211337808269693, 0.8232152752054009, 0.8254809241928713, 0.8278596934717032, 0.8304657312249207, 0.833034058307418, 0.8356665169987166, 0.8383624688491078, 0.8411244863150954, 0.8439945506417493, 0.8470157843751325, 0.8500429585684268, 0.853145754102913, 0.8563370527219475, 0.8595234628889492, 0.8627381653297159, 0.8659120975857498, 0.8690471542316381, 0.8720286692724256, 0.8748092006989953, 0.8776177253148952, 0.880403877630972, 0.8832675177379642, 0.8862006162956841, 0.8891472356032536, 0.892209413475359, 0.8953399496183538, 0.8985628183969823, 0.9016368012864895, 0.9045589548523035, 0.9073616918653066, 0.9102419134520056, 0.9132016735528475, 0.9162472518528277, 0.919263060309744, 0.9222016284893546, 0.925117116738897, 0.9273547711396215, 0.9296160116426156, 0.931903154392673, 0.9342156193576909, 0.9365501080917477, 0.9389078185947971, 0.9412857815298842, 0.9436697029354917, 0.9449380262034587, 0.8047187327409103, 0.8065572164451437, 0.808422491817132, 0.8103302898816361, 0.8123377757506371, 0.8144172685582731, 0.8166931024285032, 0.8191908656564135, 0.821811819291623, 0.8244009468064897, 0.8270534720001929, 0.8297710744788473, 0.8325538949594089, 0.8355194942783738, 0.8385414695984985, 0.8416009116441582, 0.8447478568264968, 0.8479820347725301, 0.8511617039327193, 0.8544182022396819, 0.8576006239847651, 0.8607068440482291, 0.8635856311083898, 0.8664145024978868, 0.8692489070375057, 0.8720882974050697, 0.8750044927418654, 0.8780053123874084, 0.881040238305279, 0.8841721883001759, 0.8873902150898413, 0.8906063533494568, 0.8937546124829383, 0.8966708922375615, 0.8995703130049955, 0.9025535378738756, 0.9056251910363866, 0.9087918090761185, 0.911876696039238, 0.9149435799503663, 0.9178626266460218, 0.9202033824746275, 0.9225748667014612, 0.9249775401358558, 0.9274087967364694, 0.9298700357742279, 0.9323595445361652, 0.9348756632647541, 0.937404499642584, 0.9388394918505237, 0.7960499406227226, 0.7978822196721808, 0.7997417176801402, 0.8016565444476117, 0.8036649079685895, 0.8057365402690758, 0.8080226176027798, 0.8106249720085906, 0.8132548636075341, 0.8158565046293738, 0.8185218919476208, 0.8212541156052037, 0.8240778340307906, 0.8271091010640392, 0.8301226283417561, 0.8332149955203418, 0.8363936140760748, 0.8396160891287876, 0.8428326190476859, 0.846077549675184, 0.8492849165139712, 0.8522890613547752, 0.8551326071510505, 0.8580069438970139, 0.8608504160662119, 0.863738823411973, 0.8667024711263503, 0.8697453443872691, 0.8728709856390305, 0.8760647707723227, 0.8793593358954699, 0.8825464254393425, 0.8857547652073348, 0.8886599966607636, 0.891644036704355, 0.8947192915080365, 0.8978912004886507, 0.9011661258489859, 0.9043030844360376, 0.9074845158700263, 0.9103784789580448, 0.9128127626311865, 0.9152827195894676, 0.9177854480187736, 0.9203264172661173, 0.9229020310515821, 0.9255120448453963, 0.9281547200018969, 0.9308169184981423, 0.9324142225656769, 0.7875232443471613, 0.7893436086377094, 0.791194816501315, 0.7931113926015363, 0.7951177655249728, 0.797178298039472, 0.7995158216362536, 0.8021639963619278, 0.8047965218744977, 0.8074046160009996, 0.8100779730725157, 0.8128193595640213, 0.8157159810647445, 0.8187418748646809, 0.8217708949185596, 0.8248820246758385, 0.8280850113719381, 0.8312929933399518, 0.8345329934884658, 0.8377594750852502, 0.840925786899517, 0.8438620916880336, 0.846688893722672, 0.849594888126318, 0.8524415966066866, 0.8553648305682148, 0.8583663930771456, 0.8614602707129329, 0.8646442214177774, 0.867897816918003, 0.8711854164232975, 0.8744057463259624, 0.8775696932702192, 0.8805386651503387, 0.8835984775685606, 0.8867520558071911, 0.8900111135697519, 0.8933768040656824, 0.8965511486403237, 0.8998361187592996, 0.9026761991268825, 0.9051915905532527, 0.9077453899197329, 0.9103391436035994, 0.9129766870205368, 0.915653231712946, 0.9183702161822782, 0.9211265401657212, 0.9239085729595998, 0.9256622307843778, 0.7791427337512666, 0.7809482090574293, 0.7827822820792707, 0.7846936115042167, 0.786695473213335, 0.7887412356248504, 0.7911607619103258, 0.7938131385059813, 0.796439615423603, 0.799047342053427, 0.801723461098375, 0.8044681342575901, 0.8074348464973065, 0.8104433404656044, 0.8134842333018639, 0.8166132565823235, 0.8198334041493607, 0.8230128871528469, 0.8262767229679077, 0.8294785169714153, 0.8325363330386243, 0.8354097332802266, 0.8382567106695523, 0.8411603707335107, 0.8440257855554731, 0.8469691730697749, 0.8500049930847785, 0.8531589428595922, 0.8563776229720449, 0.859680980188662, 0.8629182991741599, 0.8661948365001246, 0.8692935644949743, 0.8723183525946875, 0.8754398115991311, 0.8786612948750578, 0.8819960336911629, 0.8853785324173222, 0.8886349223459535, 0.8920108084390774, 0.8947668039346544, 0.897350151187938, 0.8999765213388349, 0.9026476714534994, 0.9053643281289585, 0.908129375225714, 0.9109393789703696, 0.9137945875411527, 0.9166820179979673, 0.9185835659344709, 0.7709041269442264, 0.7726905883338504, 0.7745150857285659, 0.7764097877144823, 0.7783973776385832, 0.7804286466025847, 0.7829196232116831, 0.7855707366206537, 0.7881868192956893, 0.7907902564493093, 0.7934609968145863, 0.7962479219183856, 0.7992355494453179, 0.8022218256295927, 0.8052700142234792, 0.8084068759540562, 0.8116041722733471, 0.8147871265782115, 0.8180364897383631, 0.8212177756381916, 0.8241647243089717, 0.826979320754242, 0.8298381543888566, 0.8327303718477592, 0.8356052997630413, 0.8385702693684337, 0.8416555769818415, 0.8448347666097554, 0.8480737617461678, 0.8513760467945357, 0.8546011456618239, 0.8579086305513289, 0.8609401053494333, 0.8640096420270549, 0.8671813182829764, 0.8704586821051008, 0.8738567306228313, 0.8772403021766604, 0.880563124253213, 0.884015808136151, 0.8866609372382568, 0.8892983029538435, 0.8919831447703531, 0.8947150022335381, 0.8974996227008556, 0.9003365562349374, 0.9032241494306353, 0.9061624434176708, 0.9091385057205664, 0.9111781423129556, 0.7628065600232734, 0.7645702204828815, 0.7663810056841338, 0.768254961797024, 0.7702275767728504, 0.7722678055213353, 0.7747917948808234, 0.7774355343369315, 0.7800379230164486, 0.7826318679054363, 0.7852940798154803, 0.7881349535471786, 0.7911160926399274, 0.7940775909311031, 0.7971288291187545, 0.8002687486984629, 0.8034278005400983, 0.8066136747954683, 0.8098256209855919, 0.8129377440010588, 0.8158026482232346, 0.8185840569610614, 0.8214473447364148, 0.8243109537907188, 0.8271961220849233, 0.8301649443345351, 0.833303587606623, 0.8364867201813861, 0.8397515607807112, 0.8429858603648505, 0.8462367190239843, 0.8495147187870837, 0.8525189454879475, 0.8556222859123686, 0.8588280159522647, 0.8621540986231022, 0.8656030416601288, 0.8689686239247065, 0.8723466979868159, 0.8757424150593552, 0.8783695550951415, 0.8810455549149325, 0.8837740350586388, 0.8865536209797157, 0.8893901820285681, 0.8922805966273653, 0.8952298321672032, 0.8982335841014544, 0.901280233164283, 0.9034460549644169, 0.7548465910048835, 0.7565831552689272, 0.7583793689014615, 0.7602307225662931, 0.7621825225380329, 0.7642327169851366, 0.7667817898623636, 0.7694149341988121, 0.7719923082514325, 0.7745707710728424, 0.7772223291823892, 0.7801129409648299, 0.7830626919119225, 0.7860186384053319, 0.7890621053029643, 0.7922004078622545, 0.7953158586186679, 0.7985001928334396, 0.8016553177260813, 0.8046473994777735, 0.8074473394867122, 0.810221481845062, 0.8130820349520972, 0.81591571612939, 0.8187954006701232, 0.821768659539883, 0.8249386681307411, 0.8281301805408261, 0.8313987892366528, 0.8345715164483303, 0.8378433021392457, 0.8410100023604105, 0.844033494828648, 0.8471598374141649, 0.8503976399310746, 0.8537567602394903, 0.8572441905087493, 0.8605746219348906, 0.8639966068011974, 0.8672504815715172, 0.8699008520058146, 0.8726026308441532, 0.8753576549388468, 0.8781690332127488, 0.8810389645688456, 0.8839689524642897, 0.8869607601881566, 0.8900113093635306, 0.8931090727589126, 0.8953872391577282, 0.7470280933332024, 0.7487354235842465, 0.7505068273667279, 0.752332400906842, 0.7542617601252846, 0.7563442280241068, 0.7588862846601672, 0.7615043660472653, 0.7640553141864136, 0.7666153904757906, 0.7692954193471293, 0.7721833263899123, 0.775097138520431, 0.7780422089230741, 0.7810761756661639, 0.7841878087070983, 0.7872707166101238, 0.790447325482852, 0.7935410081899958, 0.7964112965313755, 0.7991366353261408, 0.8019021848024178, 0.8047502724041539, 0.8075425391330253, 0.8104163054075043, 0.8134514350994846, 0.8165833963505603, 0.819767369269305, 0.8229581724374095, 0.8261343739822621, 0.8294179934206729, 0.8324693346716918, 0.835501688004779, 0.838640407454149, 0.8418947378562476, 0.8452752484045281, 0.8487493265964535, 0.852067243864409, 0.855518070943501, 0.8586048976372025, 0.8612630954282857, 0.8639747714254055, 0.8667422229116366, 0.8695687341203272, 0.8724568086485763, 0.875406062015242, 0.878421569011345, 0.8814989531867041, 0.8846268854401116, 0.8870017357218569, 0.7393455323714717, 0.7410206108227485, 0.7427677984399501, 0.7445655704467963, 0.7464619313599605, 0.7485872747417502, 0.751105095567419, 0.7537039602687569, 0.7562236728736247, 0.7587610729051659, 0.7614765640584831, 0.7643452805144582, 0.7672177416411402, 0.7701499372810163, 0.7731692059202595, 0.7762279874833826, 0.7792942544002115, 0.7824268324093767, 0.7854487395822611, 0.7882115317241936, 0.7908773869853453, 0.793624132735536, 0.7964324689639705, 0.7992015166412897, 0.802056603800971, 0.8051432931459034, 0.8082346167557964, 0.8114123604024862, 0.8145104070950249, 0.8176906416211055, 0.8209527677158879, 0.8238901614535039, 0.8269264772734524, 0.8300672149063328, 0.8333271254628951, 0.8367121289344017, 0.8401259976510038, 0.8434508498857329, 0.8469180040406895, 0.8498142596307495, 0.8524663679155633, 0.8551732880742182, 0.85793751498203, 0.8607599943084143, 0.8636481656429555, 0.8665994490010241, 0.8696175160741247, 0.8727000340758114, 0.8758355128365036, 0.8782896133956934, 0.7317970359819284, 0.7334370800261261, 0.7351569059598735, 0.7369239119822427, 0.7387954773419843, 0.7409521262850872, 0.7434348680816024, 0.7460135120586562, 0.748497508044437, 0.7510082333942874, 0.7537554506317672, 0.7566042112977956, 0.759432876155216, 0.7623404573147843, 0.7653427326940555, 0.7683439673919178, 0.7713906270317322, 0.7744545041886542, 0.7773514406595682, 0.7800295900819239, 0.782671436983873, 0.7853952142534167, 0.7881472904025185, 0.7908926618081169, 0.7937426802992819, 0.7968251278261442, 0.7999017311638723, 0.8030038102189713, 0.8060694676511694, 0.809236420475607, 0.8123703925994682, 0.8152883828628466, 0.8183090507991889, 0.8214415049237632, 0.8246960353761414, 0.8280844478865121, 0.8314181958694811, 0.8347404221975676, 0.8382098596815989, 0.8408870308269997, 0.8435181727767306, 0.8462046084448326, 0.8489472080089822, 0.8517522561373099, 0.854619375431782, 0.8575509525833312, 0.8605517019286969, 0.8636176359758659, 0.8667364034453351, 0.869250696096209, 0.7243805678690793, 0.725984971523092, 0.7276725540885578, 0.7294060448251495, 0.7312677332178099, 0.7334324402544141, 0.7358817674609339, 0.7384280674055936, 0.7408733512787197, 0.7433897168404239, 0.7461322851226296, 0.7489417771594591, 0.7517380246151617, 0.7546211315080744, 0.7575956254117193, 0.7605372420410782, 0.7635538437320623, 0.7665512571765445, 0.7693198417397634, 0.7719081455293033, 0.7745212607142451, 0.7772159898482268, 0.7799073249531603, 0.7826205406644466, 0.785525209498708, 0.7885357769458923, 0.7915828340468479, 0.7945888439065326, 0.7976321302124024, 0.800781819728231, 0.8037649396936504, 0.8066610783494387, 0.80966615310116, 0.812780395674489, 0.8160191318544182, 0.8193948681530165, 0.8226284277178203, 0.8259402927806165, 0.8292868529464075, 0.8318312675011348, 0.8344263581740695, 0.8370763030919882, 0.8397820708779407, 0.8425474750268221, 0.8453765889851553, 0.8482698396412804, 0.8512300917703203, 0.8542549272614016, 0.8573317413744287, 0.8598850590206164, 0.7170908349102988, 0.7186643911314712, 0.7203129908655106, 0.7220104187833287, 0.7238583912046984, 0.7260271736632384, 0.7284404261065314, 0.7309483544188463, 0.7333586256357454, 0.735889841607801, 0.7386070102207659, 0.7413665419192887, 0.744133631654582, 0.7469880798489866, 0.7499087899118237, 0.7528069174792722, 0.7557843304267511, 0.7586746509826495, 0.7613546672919141, 0.7638524901151379, 0.7664282394262083, 0.7690892652393345, 0.7717134293769401, 0.7743906769012875, 0.7773441980288112, 0.7802751811945259, 0.7832735664939982, 0.7861904235427002, 0.789206918616848, 0.7923268629703079, 0.7951530803811895, 0.7980225883817673, 0.8009935672000256, 0.8040796437048311, 0.8072920754352859, 0.8106238843430864, 0.8137720794382455, 0.8170574916046969, 0.8201596088930448, 0.8226546453515926, 0.8251984393634076, 0.8277956440831383, 0.8304473476949122, 0.8331569546466825, 0.8359257958262171, 0.8387594333391566, 0.84165620969435, 0.8446155769964866, 0.8476229371263626, 0.850192648230154, 0.7099327942257353, 0.7114662816020382, 0.7130728937254095, 0.7147353477799084, 0.7165660164469143, 0.7187342351872217, 0.7211098327440498, 0.7235761024393146, 0.7259478107256501, 0.7284950831629863, 0.7311766752747029, 0.7338820448036103, 0.7366198893470768, 0.739441750054364, 0.7422946908164688, 0.7451575011921989, 0.7480956165247078, 0.7508592439213986, 0.7534038645759937, 0.755861749766057, 0.7583976810974833, 0.7610159692944141, 0.7635684016673882, 0.7662339022510649, 0.7691584041312809, 0.7720478310785924, 0.7749336239568982, 0.7778152887928433, 0.780800916077435, 0.7838106417908383, 0.7865431235010701, 0.7893695681846142, 0.7923019530672352, 0.7953548090886057, 0.798530899870818, 0.8017441589822831, 0.8048519445393771, 0.8080929954690931, 0.8109330451656906, 0.8133644794822192, 0.8158416174635624, 0.818369617999994, 0.8209497426253209, 0.8235825912622916, 0.8262755174127087, 0.8290248878238302, 0.8318342535145067, 0.834702332359001, 0.8376121660897073, 0.8401737444855453, 0.7028998126371866, 0.7043948617527525, 0.705958171888678, 0.7075759214496624, 0.7093890516987904, 0.7115515219315732, 0.7138888285752243, 0.7163103891472167, 0.7186402127492518, 0.7212003948696663, 0.7238471774070461, 0.7264965992404202, 0.7291933154963381, 0.7319823583443407, 0.734764125006824, 0.7375823238603443, 0.7404512298871533, 0.7431012104905832, 0.745521651047603, 0.7479375293855188, 0.7504286770614262, 0.7529707405716585, 0.7554733729254731, 0.7581760593811829, 0.7610105506816094, 0.7638554461927637, 0.7666268521633578, 0.7694690772743589, 0.7724114338620774, 0.7752503954489506, 0.7779323289176285, 0.7807147559743368, 0.7836000170099006, 0.7866013644717578, 0.7897309522999111, 0.7928128548435209, 0.7958683048509594, 0.7990629331162498, 0.8016095837216461, 0.8039637359078061, 0.8063627957128683, 0.8088049416826181, 0.81129572644498, 0.8138346995366529, 0.8164261710940103, 0.8190712249343493, 0.8217683020151723, 0.8245188694995574, 0.8273007966189359, 0.8298279835601119, 0.6959895763902825, 0.6974441238670014, 0.6989621350292351, 0.7005373846211723, 0.7023552453658953, 0.7044756383936838, 0.7067761337575961, 0.7091501484155952, 0.7114747388274395, 0.7140050383713814, 0.7166139333228002, 0.7192045530568476, 0.7218617835730028, 0.7246066052463619, 0.7273173474620772, 0.7300880157992352, 0.7328444339560091, 0.7353957842627159, 0.737715543595659, 0.7400783595745533, 0.742522810210693, 0.7449834949357658, 0.7474340368041816, 0.7501669934118049, 0.7529071786917864, 0.7556576296152914, 0.7583563995058644, 0.761150749417525, 0.7640467946792393, 0.7667018462849096, 0.7693285263835492, 0.7720551390946822, 0.7748841630259597, 0.7778334428143062, 0.7809071256328581, 0.7838447021379982, 0.7868371077029709, 0.7899633991042061, 0.7922035377721609, 0.7944657540746454, 0.7967685885193196, 0.7991080793170626, 0.801491545059417, 0.8039171598603083, 0.8063885523517084, 0.8089033360567693, 0.8114644720347431, 0.8140672152479715, 0.8166909925927776, 0.8191554889876934, 0.6891997409509278, 0.6906118750735941, 0.6920827439493421, 0.6936170858872924, 0.6954379528705642, 0.6975130716785114, 0.6997671357133445, 0.7020942014389371, 0.7044184439077564, 0.7069081514680392, 0.709473700559563, 0.7120054176786432, 0.714620017330876, 0.7173016333365798, 0.7199480906995093, 0.7226748347765184, 0.7253049449390138, 0.727744302770723, 0.7299821400124562, 0.7322920612991374, 0.734678398565847, 0.7370558969978975, 0.7394785792239931, 0.7421995064902931, 0.7448487291139693, 0.7474796323035307, 0.7501252898004555, 0.7528643788776477, 0.755687755833508, 0.758172795961731, 0.7607383177617713, 0.7633983518510598, 0.7661664615383359, 0.7690466864494554, 0.7720399987797844, 0.7748355866797365, 0.7777534788117715, 0.7805908956170832, 0.7827177786837564, 0.7848739869891358, 0.7870615095670408, 0.7892852577669883, 0.7915432330974486, 0.7938357228669681, 0.7961628067463957, 0.7985287004811165, 0.8009250648489841, 0.803351545387705, 0.8057836555489537, 0.8081564285146408, 0.682527941607537, 0.6838958947483854, 0.6853179221455358, 0.6868244939962048, 0.6886298941170828, 0.6906575498340796, 0.6928676920146881, 0.6951382518679932, 0.6974585091176544, 0.6999087676805686, 0.7024121254655926, 0.7048985801956951, 0.7074675930642474, 0.7100715481332881, 0.7126654243502321, 0.715339691048587, 0.7178445790491613, 0.7201404193897111, 0.7223221358181049, 0.7245751205791704, 0.7269037246818462, 0.7291862522214083, 0.731632188047106, 0.7342506121432829, 0.7368418164874098, 0.7393460467919404, 0.741934807617443, 0.7446144184481284, 0.7472527678936647, 0.7496640759039757, 0.7521593697013965, 0.754750928953863, 0.7574435540901696, 0.7602497006737432, 0.7630866043325478, 0.7657994571074711, 0.7686324779031324, 0.7711438099797762, 0.7731525708794826, 0.7751894298438825, 0.7772538766647867, 0.779342480885079, 0.7814566210179348, 0.7835959640743647, 0.7857593201159347, 0.7879468508901337, 0.7901540827314161, 0.7923743032832282, 0.7945818256140238, 0.796830572423166, 0.6759718069747365, 0.6772939466151684, 0.6786655682203406, 0.6801419938425208, 0.681929300658386, 0.6839074597640742, 0.6860720263248905, 0.6882877944992427, 0.6906020440429268, 0.6930022324266378, 0.6954447658596874, 0.6978833209261529, 0.7004039687444431, 0.7029278109093673, 0.705466809306054, 0.7080739676152806, 0.7104604085839377, 0.7126140515191802, 0.7147360360868649, 0.716928260683792, 0.719193132034976, 0.7213830361374846, 0.7238418877177228, 0.726356616244271, 0.7288285438652891, 0.7312640051236838, 0.7337870991611777, 0.7364012868802008, 0.7388436196472382, 0.7411793118741279, 0.7435992789156946, 0.7461107918791131, 0.7487226722459471, 0.7514498895485318, 0.7541120718669828, 0.7567317715031386, 0.7594688027499306, 0.7616357291693681, 0.7635233582207723, 0.765426315839138, 0.7673488596743852, 0.7692855402441043, 0.7712373533761042, 0.7732032940818105, 0.7751805915384221, 0.7771676234346035, 0.7791554406671897, 0.7811384637542886, 0.7830858860605646, 0.7851778703206503, 0.6695289687717214, 0.6708037893242035, 0.6721235668688916, 0.6735676283690577, 0.6753343717112322, 0.6772611475358697, 0.6793786076494172, 0.6815523084151358, 0.6838429824045168, 0.6861954685301239, 0.6885671790457109, 0.690958829490803, 0.6934285053483943, 0.6958674613572206, 0.6983519211152522, 0.7008398644957137, 0.7031454437836011, 0.7051624975853336, 0.7072241784552452, 0.7093520262431052, 0.7115212494735812, 0.7136544650031869, 0.7161165962797177, 0.718518807371169, 0.7208639585443075, 0.7232315140410194, 0.7256826097720768, 0.7282220875643919, 0.7304672030843471, 0.7327206634709589, 0.7350582804837609, 0.7374836142859791, 0.7400099414493558, 0.7426436868420468, 0.74512446615356, 0.7476414619178317, 0.7502721557474008, 0.7520768429317264, 0.7538254185068954, 0.7555814101963927, 0.7573470572738294, 0.7591200097112449, 0.7608908997700733, 0.7626629653797281, 0.7644315645842429, 0.7661901787671628, 0.7679329703199131, 0.7696476932671975, 0.7712984524443405, 0.7731987682747337, 0.663197070942602, 0.6644231854674764, 0.6656897983931541, 0.6670994266623878, 0.6688432847245822, 0.6707169285029753, 0.6727858669677598, 0.6749426199542965, 0.6771800231197727, 0.6794826834546881, 0.681786058755409, 0.684120784363336, 0.6865393544864109, 0.6888921043127848, 0.6913203280716631, 0.6936784304826981, 0.6958642367487561, 0.6977923062684207, 0.6997837013966414, 0.7018468038702863, 0.7039168218094393, 0.7060568520881222, 0.7084322656432142, 0.7107308356755007, 0.7129552493959714, 0.7152500728328034, 0.7176268431707955, 0.7200291854537765, 0.7221258653458023, 0.7242929022661165, 0.7265399298251345, 0.7288738755563502, 0.7313031434031714, 0.7338190214234862, 0.7361307635788421, 0.7385361481329027, 0.7408824599154769, 0.742475700989348, 0.7440691049806093, 0.7456684264786898, 0.7472620485712075, 0.7488468259107965, 0.7504225627901241, 0.751980081896067, 0.7535170528163957, 0.755024387279475, 0.7564904261513391, 0.7579035426850036, 0.7592207603927552, 0.7608927628098094, 0.6569713705855731, 0.6581470715292695, 0.6593621468136162, 0.6607354127606995, 0.6624542041502023, 0.6642730967049484, 0.6662922057528551, 0.6684297549652302, 0.6706118259380792, 0.6728626743231894, 0.6750958899522416, 0.6773758750421933, 0.6797063565456534, 0.6820020501538857, 0.6843715085073188, 0.6865984103649715, 0.6886390374089042, 0.6904994534817082, 0.6924216583012858, 0.6944095184392882, 0.6963803267398779, 0.6985247894002358, 0.7007854321043141, 0.7029577515585314, 0.7051007990223084, 0.7073209778559604, 0.7096185143827646, 0.7118156568784392, 0.7138217106649415, 0.7158963176247446, 0.7180461240617997, 0.7202816570254682, 0.7226076133928041, 0.7249349842840198, 0.7271278942076287, 0.729411767120804, 0.7313889195038153, 0.7328285498784455, 0.7342628382866649, 0.7356834331050193, 0.7370904042761575, 0.7384783638089092, 0.739837479043067, 0.7411601695389521, 0.7424417442182976, 0.7436689625528856, 0.7448339993584241, 0.7459094194238575, 0.7468544818734024, 0.7482600714188159, 0.6508548328715889, 0.651979436893548, 0.6531357711134951, 0.6544736128534131, 0.6561652889737974, 0.6579279327482749, 0.6598960071174294, 0.662010666330038, 0.6641370194905061, 0.6663341993373018, 0.6684955551032346, 0.6707187488445726, 0.6729627105818877, 0.675193121780769, 0.6774821661664513, 0.6795993315798842, 0.6814937407531569, 0.6832837610875422, 0.6851338638672485, 0.6870478591500228, 0.6889086751373126, 0.6910586728769725, 0.6932012423075411, 0.6952453517825702, 0.6973078133884941, 0.6994453419643956, 0.7016589625686949, 0.7036462060812951, 0.7055549655464894, 0.7075330421547548, 0.7095813627835835, 0.7117102688548295, 0.71392740676723, 0.7160542394162981, 0.7181223050491992, 0.7202757782309532, 0.7218725172026363, 0.7231480295092977, 0.7244026656694256, 0.7256400616032904, 0.7268453232605776, 0.7280122276425551, 0.7291369077494025, 0.7302062868485666, 0.7312102067638397, 0.7321338125435426, 0.7329625895265671, 0.7336692230519641, 0.7342018247737736, 0.7353006725742786, 0.6448422255443831, 0.6459146545359344, 0.6470145480077871, 0.6483094211987535, 0.6499746992902127, 0.6516797107564565, 0.6535956408689476, 0.655682315554148, 0.6577542086437429, 0.6598928747272303, 0.6619838998991526, 0.664148380536774, 0.6663036969940366, 0.6684720831832581, 0.6706550549951158, 0.6726806444618083, 0.67442792064519, 0.6761449578875434, 0.6779202062395594, 0.6797574081900347, 0.681563179456782, 0.6836550282403961, 0.6856765249994485, 0.6875938201293973, 0.6895731495775972, 0.6916218453936472, 0.6937376206749286, 0.6955223366264998, 0.6973315321521698, 0.6992049915276468, 0.7011458309476628, 0.7031611823249347, 0.705262863435788, 0.7071821478089209, 0.709117101909013, 0.7111346139866048, 0.7123299497571636, 0.7134299089976014, 0.7145015066691667, 0.7155334225642191, 0.7165226717772795, 0.7174601723651869, 0.7183314825963384, 0.7191241541966833, 0.7198268948731916, 0.7204201941339785, 0.7208819916006567, 0.7211848344822935, 0.7212639237132115, 0.7220145423034148, 0.6389313105119921, 0.6399505758391035, 0.6409931013161173, 0.6422516114950856, 0.6438780247330578, 0.6455267045352183, 0.6473894706705725, 0.6494460751177448, 0.6514619810948211, 0.6535280688492582, 0.6555597401109373, 0.6576637080688749, 0.6597294205827858, 0.6618337931387415, 0.6639134808336139, 0.6658335173593988, 0.6674410766737198, 0.6690826907109986, 0.6707804842123142, 0.6725130073838773, 0.6743094163512758, 0.6763058379962328, 0.6781737516249441, 0.6800049430208951, 0.6818974677613638, 0.6838566994324105, 0.6857911892916729, 0.6874453830335109, 0.6891500534404794, 0.6909121778923402, 0.6927414925119512, 0.6946392073366496, 0.6965884757185105, 0.6983215191811496, 0.7001176153223965, 0.7018199773691325, 0.7027684318115511, 0.7036822694190354, 0.7045545100002792, 0.7053772746867475, 0.706135749630565, 0.7068194037503909, 0.7074199382562488, 0.7079183335854025, 0.70829615656144, 0.7085321390054042, 0.708598656079633, 0.7084590505155882, 0.7080486909699855, 0.7084016541954478, 0.6331198853074453, 0.6340850835673242, 0.6350718756448415, 0.6363086718214617, 0.6378790456148495, 0.6394646654387992, 0.6413096034212274, 0.6433004156145135, 0.6452589132076051, 0.6472511348673018, 0.649221867171992, 0.6512636395165111, 0.6532388742239708, 0.6552773639482857, 0.657230057009521, 0.6590169423892704, 0.6605292175056185, 0.6620965345339842, 0.6637144173156999, 0.6653369829742076, 0.6671249152986392, 0.6689991579401057, 0.6707335051975596, 0.6724791503355136, 0.6742813040668969, 0.6761472326336633, 0.6778683828125904, 0.6794165175607235, 0.681011911950276, 0.682660456797906, 0.6843701232586168, 0.6861441589279649, 0.6878805915240108, 0.689474058427912, 0.6911215534429681, 0.6924267240785389, 0.6931914352558141, 0.6939122649976611, 0.6945701725229477, 0.6951658155909017, 0.6956793928121322, 0.6961016312896018, 0.6964121976464207, 0.696592659049349, 0.6966222410338879, 0.6964735914851969, 0.6961133001411516, 0.6954934487610746, 0.6947133102768452, 0.6944623232232741, 0.6274058174600905, 0.6283160933374706, 0.6292560179899485, 0.6304595379466172, 0.6319728630626507, 0.6334973658639629, 0.6353196790953264, 0.6372410010198506, 0.6391435751286474, 0.6410607401254951, 0.6429690550078266, 0.6449276583959362, 0.6468310200788797, 0.6487908627973049, 0.6506224873024284, 0.6522645165267018, 0.6536992468628282, 0.6551860016073331, 0.6567216564147939, 0.65823202101798, 0.6600095361044783, 0.6617592471735054, 0.6633627136299304, 0.6650133072059838, 0.6667250796807707, 0.6684940453690074, 0.6699986779728495, 0.6714342562767701, 0.672918338399749, 0.6744483595521028, 0.6760313962676152, 0.6776778736407725, 0.679196997844422, 0.6806421317453821, 0.6821343111843943, 0.6830326484370619, 0.6836050226040238, 0.6841161429090663, 0.6845559440945753, 0.6849080573418405, 0.6851672793025977, 0.6853031974847824, 0.6853105095702308, 0.6851515538222694, 0.6848093062852664, 0.6842484115852996, 0.6834266440260857, 0.6823516839713178, 0.6813499127055134, 0.6834376168567597, 0.6217894817047525, 0.6226415553873752, 0.6235334447711074, 0.6247023471507642, 0.6261576974367347, 0.6276200860002117, 0.6294142949902433, 0.6312723627812011, 0.6331117173009113, 0.6349555453130715, 0.6368000659003391, 0.6386690812711415, 0.6405047965222148, 0.6423610343250938, 0.6440942859529222, 0.6455910195449154, 0.6469462913603135, 0.6483475709657605, 0.6498017893109804, 0.6512683579319459, 0.6529630743875907, 0.6545523756614848, 0.6560579202282362, 0.6576151522024075, 0.6592291150831863, 0.6608833224873707, 0.662182820914173, 0.663505336766554, 0.6648704198399646, 0.6662771771729159, 0.6677315362346479, 0.6692420309688972, 0.6705375362916619, 0.6718279230187041, 0.6731577872004184, 0.6736362353347233, 0.6740063996134035, 0.6743007281279969, 0.6745071921633008, 0.6746118238893729, 0.6745931323586078, 0.6744362243348658, 0.674113577752445, 0.6735995056161692, 0.6728618896151883, 0.6718603786553898, 0.6706268038740987, 0.6696376410449155, 0.6727489455009349, 0.6773066371463587, 0.6162661641649312, 0.6170594561843965, 0.6179022329435742, 0.6190352626131781, 0.6204317901267089, 0.6218311499431722, 0.6235955469961436, 0.6253896709439651, 0.6271679806796935, 0.6289313831981777, 0.6307136522432679, 0.6324924925534909, 0.6342591231818406, 0.6360107248767406, 0.6376445611219594, 0.6389956491915965, 0.64026965553024, 0.6415871881456896, 0.6429511126736119, 0.6443776566669557, 0.6459813167311439, 0.6474078441140317, 0.6488195743197389, 0.6502804153116685, 0.6517904881099407, 0.6532472022995819, 0.6544214415866063, 0.6556270124677133, 0.6568664862139035, 0.6581480617995771, 0.6594687718196706, 0.6607980437609599, 0.6619040412071224, 0.6630328631910981, 0.6640034935281021, 0.6642421698107128, 0.6644013508878515, 0.664469147067495, 0.6644313756917151, 0.6642716100435854, 0.6639660153821061, 0.663495845230861, 0.6628303735879612, 0.6619406348302151, 0.6607822246599185, 0.6594883396068686, 0.6602131556847926, 0.6632923986329363, 0.6664657780809631, 0.6710540564085428, 0.6108338262046891, 0.611567819696792, 0.6123604916084691, 0.6134564751735451, 0.6147934056393308, 0.61612890023649, 0.6178623311158767, 0.6195914233930235, 0.6213076313522263, 0.6229929861711739, 0.6247085625652318, 0.6263967019132809, 0.6280929059440756, 0.6297389294353688, 0.6312638092353198, 0.6324775662619754, 0.6336686088114696, 0.6349005727264576, 0.6361655468708278, 0.6375541840645635, 0.6390351767880318, 0.6403312730727584, 0.6416474145685352, 0.6430091174264705, 0.6444164026132999, 0.6456531111730356, 0.646715065475997, 0.6477999788951141, 0.6489134475318395, 0.6500620422455563, 0.651244331582161, 0.652350678669189, 0.653298196057962, 0.6542607017399632, 0.6548190881298322, 0.6548536527687473, 0.6547947368012131, 0.654627203861534, 0.6543351082025286, 0.6538954295004189, 0.6532936906386604, 0.6524949063690475, 0.6514673254865853, 0.6501756317137153, 0.648911592085382, 0.6509040448844532, 0.6538549528273606, 0.6569128045162022, 0.6600691912591599, 0.664679874643312, 0.6054904716435514, 0.606164708359985, 0.6069063633796955, 0.6079642047729401, 0.609240833280888, 0.610511699850603, 0.6122130729165135, 0.6138761310975156, 0.6155292587881916, 0.6171357124105077, 0.6187814518315136, 0.6203805138622762, 0.6220050393722013, 0.6235446276257794, 0.6249329447207606, 0.6260359063834839, 0.6271423896046753, 0.628287071859353, 0.6294365418347894, 0.6308047285765916, 0.632144205651939, 0.6333223698654122, 0.6345412511510793, 0.6358012115937692, 0.6371022079997469, 0.6381218459261105, 0.639064123118503, 0.6400248294441573, 0.6410084254642525, 0.642017147207685, 0.6430593094003053, 0.6439378404176512, 0.6447215430086869, 0.6455116084234476, 0.6456484961077201, 0.6454720945000803, 0.6451849898628303, 0.644771822121883, 0.6442141885346369, 0.643490396991189, 0.6425701743925574, 0.641427163155018, 0.640021261298183, 0.6389465607902265, 0.6416650313936659, 0.6444809551514985, 0.6474007036814319, 0.6504287266994397, 0.6535590167186491, 0.6581840918506656, 0.600234147204728, 0.600848223771068, 0.6015380251817808, 0.602556701587736, 0.6037715162889759, 0.6049784996021145, 0.6066462158254711, 0.6082423199483351, 0.6098314642508715, 0.6113582338897097, 0.6129363940839211, 0.6144402279545469, 0.615980706059921, 0.617423108835909, 0.6186783627994379, 0.6196697843512948, 0.6206902124392188, 0.6217460008607159, 0.62284097630917, 0.6241247339436156, 0.6252984861655597, 0.6263807942210086, 0.6275008457921296, 0.6286565921643948, 0.6298366064667104, 0.6306493442009308, 0.6314655273240495, 0.6323020661213966, 0.6331520858483974, 0.6340208020440823, 0.6349147010302516, 0.6355607490612344, 0.6361739683192447, 0.6367841031693257, 0.6364962554245861, 0.636099763606695, 0.6355763743165754, 0.6349084661582101, 0.6340750135317499, 0.6330512628138758, 0.6318036377393689, 0.6303013100392225, 0.6299390934432851, 0.6325231916906554, 0.6351967951579673, 0.6379710192746413, 0.6408512770819909, 0.6438425180455324, 0.6469366078746134, 0.6515667080306043]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(A, b, test_size=.3, random_state=SEED)\n",
    "\n",
    "scores = []\n",
    "a_sk = np.linspace(0.01, 1, 50)\n",
    "b_sk = np.linspace(0.01, 1, 50)\n",
    "comb_sk = [(a_sk[i], b_sk[j]) for i in range(len(a_sk)) for j in range(len(b_sk))]\n",
    "\n",
    "for alph, lambd in comb_sk:\n",
    "    eNet = ElasticNet(alpha=alph, l1_ratio=lambd, max_iter=10000, random_state=SEED)\n",
    "    eNet.fit(X_train, y_train)\n",
    "    scores.append(eNet.score(X_test, y_test))\n",
    "    \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 1.0\n"
     ]
    }
   ],
   "source": [
    "alph_best, lambd_best = comb_sk[np.argmax(scores)]\n",
    "print(alph_best, lambd_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make enet !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9991717628306662\n"
     ]
    }
   ],
   "source": [
    "eNet = ElasticNet(alpha=alph_best, l1_ratio=lambd_best, max_iter=10000, random_state=SEED)\n",
    "eNet.fit(X_train, y_train)\n",
    "print(eNet.score(X_test, y_test))\n",
    "alphas_enet, coefs_enet, _ = enet_path(\n",
    "    A, b, alpha=alph_best, l1_ratio=lambd_best, fit_intercept=False) #chose the best alpha "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with LASSO first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006017635143010125, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.020836353133958596, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009390298233807215, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011759277646300248, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018287019727065257, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007079929969049381, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.014781304365726555, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.005553968334909953, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04429118990771297, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.045510559268966855, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.023401861689652748, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03399479452032628, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.031387423935976155, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05426422911007611, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.045173609279536286, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0431524443936635, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04090250750787572, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.044464441566815616, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04485411887476798, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.038186932224121506, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0574141772741148, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03978682702119363, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02048285430765473, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03309145988159523, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.037271236712264066, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05942464277691517, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04775371890183844, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.021656678113934236, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.029106485201023435, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04330580384993854, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.057846629806706185, tolerance: 0.0030132098962350243\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05301578616867597, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.023700935526050237, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03674184015772175, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05299918759038258, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.045696246040053845, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05570289198101874, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.021208038144283625, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04392080106435392, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.048422430170400155, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.038046283145776405, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.060626648473991906, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018121519003039044, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.038216603214126454, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05306798829321313, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.039243182685746, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03753925600659902, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018112530923367842, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0188447550492421, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.059778667485121506, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03994080113973275, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03669768924646033, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.028315235805472128, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01662210966557942, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.048555102357200064, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04243744471680433, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.037318933235831686, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.032763660521446414, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01860889250887754, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.031325250588318476, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04478094435187818, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03741907676585576, tolerance: 0.002599428791221946\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03498335321638346, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.016800818409980822, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.029524518531270805, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.044825516058370596, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03881486166701209, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03679312581546901, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.015482854937904134, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.029378186420593977, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04538665019592625, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03889732618134145, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.038054939512552344, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02873062699733242, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02992524588182477, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.07736283492726437, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.20425158373386365, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04103678761137075, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2702620928167463, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09972657367348153, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.18509589099560833, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.31360049396607703, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2677609605226896, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2716317199264209, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.18868996652502487, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2266218917495854, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2879053818977435, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2813474880993597, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.26812540829575987, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2598893608493478, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2544891494456253, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.28367350257214835, tolerance: 0.002599428791221946\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.27309207897513865, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2715866947826392, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.27972496346073994, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.26865068967160727, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.27912383528937307, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.27596066036892564, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2664863390978758, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2872599278808419, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2768092834762863, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.26930995009664094, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.27458228714049654, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.26125791868630405, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2897602448862494, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2835125765279762, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2613976496772506, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2735673205310636, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2575086944082243, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2905268901082969, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.28661053161056416, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2561159235106888, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2729054947152578, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2551140905761377, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.29074322356970056, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.288137109213005, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.25284495257903256, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2725037208713014, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2536602449851324, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.29079409194644557, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.28891584300468975, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2508905243118127, tolerance: 0.002599428791221946\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2722670072630549, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.25279965801832144, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2907992546742277, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.28933109854689076, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.24974396658125117, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.27212941346057723, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2522971088397811, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2907943211355367, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2895590386032964, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.24907795315712064, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2720499357649876, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.25200586380519246, tolerance: 0.0027829856910426176\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.29078889759067683, tolerance: 0.002744508445159628\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2896864297992387, tolerance: 0.0030132098962350243\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2486931798736002, tolerance: 0.002599428791221946\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.27200417911154035, tolerance: 0.002810763144722324\n",
      "  positive)\n",
      "/home/tanglef/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06068449014340782, tolerance: 0.0034877239920953853\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "alpha_max = 1\n",
    "n_alphas = 30\n",
    "eps = 1e-7\n",
    "\n",
    "alphas = np.logspace(np.log10(alpha_max), np.log10(alpha_max * eps),\n",
    "                     num=n_alphas)\n",
    "_, x_lasso, _ = lasso_path(A, b, alphas=alphas, fit_intercept=False,\n",
    "                               return_models=False)\n",
    "\n",
    "coef_lslasso, index_lslasso = LSLassoCV(A, b, alphas, cv=5, max_iter=100000,\n",
    "                                        tol=1e-7, fit_intercept=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x_true, 'k', label=\"True signal\")\n",
    "ax.plot(x_lasso[:, index_lslasso], '--', label=\"Lasso\")\n",
    "#ax.plot(coefs_enet, '--', label=\"enet\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
